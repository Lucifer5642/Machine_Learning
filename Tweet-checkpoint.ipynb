{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "016557ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\khara\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\khara\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\khara\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "import string\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "609c4bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-04 22:22:53+00:00</td>\n",
       "      <td>Here is a good example of the comprehension of...</td>\n",
       "      <td>sean</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Owner of @TeczrMedia @Teczr @Bullpen_RE | Rick...</td>\n",
       "      <td>2014-04-02 19:11:03+00:00</td>\n",
       "      <td>1681</td>\n",
       "      <td>869</td>\n",
       "      <td>21493</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-04 22:21:25+00:00</td>\n",
       "      <td>How to generate a SWOT Analysis with AI¬†\\n#jed...</td>\n",
       "      <td>Jeda Ai ‚Äî World‚Äôs First AI Workspace Canvas</td>\n",
       "      <td>Silicon Valley, California</td>\n",
       "      <td>üëã https://t.co/X4Wzbh5oO1 ‚Äî Unleash maximum pr...</td>\n",
       "      <td>2020-08-28 22:36:20+00:00</td>\n",
       "      <td>6754</td>\n",
       "      <td>126</td>\n",
       "      <td>1094</td>\n",
       "      <td>False</td>\n",
       "      <td>['jedaai', 'ai', 'chatgpt', 'gpt4']</td>\n",
       "      <td>Metricool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date  \\\n",
       "0  2023-04-04 22:22:53+00:00   \n",
       "1  2023-04-04 22:21:25+00:00   \n",
       "\n",
       "                                                text  \\\n",
       "0  Here is a good example of the comprehension of...   \n",
       "1  How to generate a SWOT Analysis with AI¬†\\n#jed...   \n",
       "\n",
       "                                     user_name               user_location  \\\n",
       "0                                         sean                      Canada   \n",
       "1  Jeda Ai ‚Äî World‚Äôs First AI Workspace Canvas  Silicon Valley, California   \n",
       "\n",
       "                                    user_description  \\\n",
       "0  Owner of @TeczrMedia @Teczr @Bullpen_RE | Rick...   \n",
       "1  üëã https://t.co/X4Wzbh5oO1 ‚Äî Unleash maximum pr...   \n",
       "\n",
       "                user_created  user_followers  user_friends  user_favourites  \\\n",
       "0  2014-04-02 19:11:03+00:00            1681           869            21493   \n",
       "1  2020-08-28 22:36:20+00:00            6754           126             1094   \n",
       "\n",
       "   user_verified                             hashtags           source  \n",
       "0          False                                  NaN  Twitter Web App  \n",
       "1          False  ['jedaai', 'ai', 'chatgpt', 'gpt4']        Metricool  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = pd.read_csv(\"D://Khara/AllFolder/Data Sets/tweets.csv\")\n",
    "data_url.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2a54c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here is a good example of the comprehension of...</td>\n",
       "      <td>sean</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Owner of @TeczrMedia @Teczr @Bullpen_RE | Rick...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to generate a SWOT Analysis with AI¬†\\n#jed...</td>\n",
       "      <td>Jeda Ai ‚Äî World‚Äôs First AI Workspace Canvas</td>\n",
       "      <td>Silicon Valley, California</td>\n",
       "      <td>üëã https://t.co/X4Wzbh5oO1 ‚Äî Unleash maximum pr...</td>\n",
       "      <td>['jedaai', 'ai', 'chatgpt', 'gpt4']</td>\n",
       "      <td>Metricool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Microsoft Research head Peter Lee on the appli...</td>\n",
       "      <td>Jerome P. Lisk, M.D., FAAN</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>Biotech Advisor @LikemindsGlobal @Beneufit,@Re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://t.co/MJmg5pCO23 is available for purch...</td>\n",
       "      <td>DNBX.com</td>\n",
       "      <td>Australia</td>\n",
       "      <td>A great brand starts with an even greater name...</td>\n",
       "      <td>['domains', 'domainnames', 'digitalassets', 'g...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Welcome aboard @Probe_AI to the GPT Feed(https...</td>\n",
       "      <td>Felipe Barcelos</td>\n",
       "      <td>üü©üü©üü©üü©üü©üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú 12 M. SaaS</td>\n",
       "      <td>Tech entrepreneur building 12 public Micro Saa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29487</th>\n",
       "      <td>#gpt4 also #brootswasright https://t.co/tMTUiN...</td>\n",
       "      <td>Clone ‚ùå God</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kawaii skulls are the most original Japanese p...</td>\n",
       "      <td>['gpt4', 'brootswasright']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29488</th>\n",
       "      <td>How much energy does it take to train #GPT4, t...</td>\n",
       "      <td>Adam Ai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Exploring the future of human-AI conversation ...</td>\n",
       "      <td>['GPT4']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29489</th>\n",
       "      <td>It looks like VIDEO is dominating the GPT-4 po...</td>\n",
       "      <td>Intercept</td>\n",
       "      <td>Toronto, Ontario</td>\n",
       "      <td>B2B marketing agency helping global technology...</td>\n",
       "      <td>['gpt4']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29490</th>\n",
       "      <td>The perfect storm is brewing, with the upcomin...</td>\n",
       "      <td>Dante</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>‚ö°Ô∏è‚ö°Ô∏è‚ö°Ô∏è‚ö°Ô∏è‚ö°Ô∏è</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29491</th>\n",
       "      <td>On the horizon - #GPT4 and why it matters. | T...</td>\n",
       "      <td>MohitRajhans</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>https://t.co/WoZTkrbAPGüéû blog since 99' /Amazo...</td>\n",
       "      <td>['GPT4']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29492 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      Here is a good example of the comprehension of...   \n",
       "1      How to generate a SWOT Analysis with AI¬†\\n#jed...   \n",
       "2      Microsoft Research head Peter Lee on the appli...   \n",
       "3      https://t.co/MJmg5pCO23 is available for purch...   \n",
       "4      Welcome aboard @Probe_AI to the GPT Feed(https...   \n",
       "...                                                  ...   \n",
       "29487  #gpt4 also #brootswasright https://t.co/tMTUiN...   \n",
       "29488  How much energy does it take to train #GPT4, t...   \n",
       "29489  It looks like VIDEO is dominating the GPT-4 po...   \n",
       "29490  The perfect storm is brewing, with the upcomin...   \n",
       "29491  On the horizon - #GPT4 and why it matters. | T...   \n",
       "\n",
       "                                         user_name  \\\n",
       "0                                             sean   \n",
       "1      Jeda Ai ‚Äî World‚Äôs First AI Workspace Canvas   \n",
       "2                       Jerome P. Lisk, M.D., FAAN   \n",
       "3                                         DNBX.com   \n",
       "4                                  Felipe Barcelos   \n",
       "...                                            ...   \n",
       "29487                                  Clone ‚ùå God   \n",
       "29488                                      Adam Ai   \n",
       "29489                                    Intercept   \n",
       "29490                                        Dante   \n",
       "29491                                 MohitRajhans   \n",
       "\n",
       "                    user_location  \\\n",
       "0                          Canada   \n",
       "1      Silicon Valley, California   \n",
       "2                      Dallas, TX   \n",
       "3                       Australia   \n",
       "4         üü©üü©üü©üü©üü©üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú 12 M. SaaS   \n",
       "...                           ...   \n",
       "29487                         NaN   \n",
       "29488                         NaN   \n",
       "29489            Toronto, Ontario   \n",
       "29490               Manhattan, NY   \n",
       "29491                     Toronto   \n",
       "\n",
       "                                        user_description  \\\n",
       "0      Owner of @TeczrMedia @Teczr @Bullpen_RE | Rick...   \n",
       "1      üëã https://t.co/X4Wzbh5oO1 ‚Äî Unleash maximum pr...   \n",
       "2      Biotech Advisor @LikemindsGlobal @Beneufit,@Re...   \n",
       "3      A great brand starts with an even greater name...   \n",
       "4      Tech entrepreneur building 12 public Micro Saa...   \n",
       "...                                                  ...   \n",
       "29487  kawaii skulls are the most original Japanese p...   \n",
       "29488  Exploring the future of human-AI conversation ...   \n",
       "29489  B2B marketing agency helping global technology...   \n",
       "29490                                         ‚ö°Ô∏è‚ö°Ô∏è‚ö°Ô∏è‚ö°Ô∏è‚ö°Ô∏è   \n",
       "29491  https://t.co/WoZTkrbAPGüéû blog since 99' /Amazo...   \n",
       "\n",
       "                                                hashtags              source  \n",
       "0                                                    NaN     Twitter Web App  \n",
       "1                    ['jedaai', 'ai', 'chatgpt', 'gpt4']           Metricool  \n",
       "2                                                    NaN  Twitter for iPhone  \n",
       "3      ['domains', 'domainnames', 'digitalassets', 'g...     Twitter Web App  \n",
       "4                                                    NaN     Twitter Web App  \n",
       "...                                                  ...                 ...  \n",
       "29487                         ['gpt4', 'brootswasright']     Twitter Web App  \n",
       "29488                                           ['GPT4']     Twitter Web App  \n",
       "29489                                           ['gpt4']     Twitter Web App  \n",
       "29490                                                NaN  Twitter for iPhone  \n",
       "29491                                           ['GPT4']  Twitter for iPhone  \n",
       "\n",
       "[29492 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_drop = data_url.drop(['date', 'user_created', 'user_followers', 'user_friends', 'user_favourites', 'user_verified'], axis=1)\n",
    "column_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d2db5349",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [column_drop]\n",
    "\n",
    "last = column_drop.dtypes\n",
    "\n",
    "\n",
    "data_url_1 = column_drop\n",
    "\n",
    "data_url_1 = data_url_1.astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12dcc386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>text_no_puctuation</th>\n",
       "      <th>user_description_no_puctuation</th>\n",
       "      <th>user_location_no_puctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sean</td>\n",
       "      <td>nan</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Here is a good example of the comprehension of...</td>\n",
       "      <td>Owner of TeczrMedia Teczr BullpenRE  Rickey Du...</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jeda Ai ‚Äî World‚Äôs First AI Workspace Canvas</td>\n",
       "      <td>['jedaai', 'ai', 'chatgpt', 'gpt4']</td>\n",
       "      <td>Metricool</td>\n",
       "      <td>How to generate a SWOT Analysis with AI¬†\\njeda...</td>\n",
       "      <td>üëã httpstcoX4Wzbh5oO1 ‚Äî Unleash maximum product...</td>\n",
       "      <td>Silicon Valley California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jerome P. Lisk, M.D., FAAN</td>\n",
       "      <td>nan</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Microsoft Research head Peter Lee on the appli...</td>\n",
       "      <td>Biotech Advisor LikemindsGlobal BeneufitReachM...</td>\n",
       "      <td>Dallas TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DNBX.com</td>\n",
       "      <td>['domains', 'domainnames', 'digitalassets', 'g...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>httpstcoMJmg5pCO23 is available for purchase\\n...</td>\n",
       "      <td>A great brand starts with an even greater name...</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Felipe Barcelos</td>\n",
       "      <td>nan</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Welcome aboard ProbeAI to the GPT Feedhttpstco...</td>\n",
       "      <td>Tech entrepreneur building 12 public Micro Saa...</td>\n",
       "      <td>üü©üü©üü©üü©üü©üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú 12 M SaaS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     user_name  \\\n",
       "0                                         sean   \n",
       "1  Jeda Ai ‚Äî World‚Äôs First AI Workspace Canvas   \n",
       "2                   Jerome P. Lisk, M.D., FAAN   \n",
       "3                                     DNBX.com   \n",
       "4                              Felipe Barcelos   \n",
       "\n",
       "                                            hashtags              source  \\\n",
       "0                                                nan     Twitter Web App   \n",
       "1                ['jedaai', 'ai', 'chatgpt', 'gpt4']           Metricool   \n",
       "2                                                nan  Twitter for iPhone   \n",
       "3  ['domains', 'domainnames', 'digitalassets', 'g...     Twitter Web App   \n",
       "4                                                nan     Twitter Web App   \n",
       "\n",
       "                                  text_no_puctuation  \\\n",
       "0  Here is a good example of the comprehension of...   \n",
       "1  How to generate a SWOT Analysis with AI¬†\\njeda...   \n",
       "2  Microsoft Research head Peter Lee on the appli...   \n",
       "3  httpstcoMJmg5pCO23 is available for purchase\\n...   \n",
       "4  Welcome aboard ProbeAI to the GPT Feedhttpstco...   \n",
       "\n",
       "                      user_description_no_puctuation  \\\n",
       "0  Owner of TeczrMedia Teczr BullpenRE  Rickey Du...   \n",
       "1  üëã httpstcoX4Wzbh5oO1 ‚Äî Unleash maximum product...   \n",
       "2  Biotech Advisor LikemindsGlobal BeneufitReachM...   \n",
       "3  A great brand starts with an even greater name...   \n",
       "4  Tech entrepreneur building 12 public Micro Saa...   \n",
       "\n",
       "  user_location_no_puctuation  \n",
       "0                      Canada  \n",
       "1   Silicon Valley California  \n",
       "2                   Dallas TX  \n",
       "3                   Australia  \n",
       "4      üü©üü©üü©üü©üü©üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú 12 M SaaS  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the puctuation in the datasets\n",
    "def remove_punctuation(text):\n",
    "    no_punct=[words for words in text if words not in string.punctuation]\n",
    "    words_wo_punct=''.join(no_punct)\n",
    "    return words_wo_punct\n",
    "data_url_1['text_no_puctuation']=data_url_1['text'].apply(lambda x: remove_punctuation(x))\n",
    "data_url_1['user_description_no_puctuation']=data_url_1['user_description'].apply(lambda x: remove_punctuation(x))\n",
    "data_url_1['user_location_no_puctuation']=data_url_1['user_location'].apply(lambda x: remove_punctuation(x))\n",
    "\n",
    "data = data_url_1.drop(['text', 'user_description', 'user_location'], axis=1)\n",
    "\n",
    "data_url_1 = data\n",
    "\n",
    "data_url_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c0c1029",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'user_description_no_puctuation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'user_description_no_puctuation'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-cb20727c233f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#data_url_1['text_wo_punct_split']=data_url_1['text_no_puctuation'].apply(lambda x: tokenize(x.lower()))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdata_url_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_description_no_puctuation_split'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_url_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_description_no_puctuation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mdata_url_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_location_no_puctuation_split'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_url_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_location_no_puctuation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdata_url_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_name_split'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_url_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'user_description_no_puctuation'"
     ]
    }
   ],
   "source": [
    "# This is for the tokenize the data which means we are the split the data \n",
    "\n",
    "def tokenize(text):\n",
    "    split=re.split(\"\\W+\",text) \n",
    "    return split\n",
    "data_url_1['text_wo_punct_split']=data_url_1['text_no_puctuation'].apply(lambda x: tokenize(x.lower()))\n",
    "data_url_1['user_description_no_puctuation_split']=data_url_1['user_description_no_puctuation'].apply(lambda x: tokenize(x.lower()))\n",
    "data_url_1['user_location_no_puctuation_split']=data_url_1['user_location_no_puctuation'].apply(lambda x: tokenize(x.lower()))\n",
    "data_url_1['user_name_split']=data_url_1['user_name'].apply(lambda x: tokenize(x.lower()))\n",
    "data_url_1['hashtags_split']=data_url_1['hashtags'].apply(lambda x: tokenize(x.lower()))\n",
    "data_url_1['source_split']=data_url_1['source'].apply(lambda x: tokenize(x.lower()))\n",
    "\n",
    "data_url_1 = data_url_1.drop(['user_name', 'hashtags', 'source', 'text_no_puctuation', 'user_description_no_puctuation', 'user_location_no_puctuation'], axis=1)\n",
    "data_url_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ddae3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_wo_punct_split</th>\n",
       "      <th>user_description_no_puctuation_split</th>\n",
       "      <th>user_location_no_puctuation_split</th>\n",
       "      <th>user_name__split</th>\n",
       "      <th>user_name_split</th>\n",
       "      <th>hashtags_split</th>\n",
       "      <th>source_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[here, is, a, good, example, of, the, comprehe...</td>\n",
       "      <td>[owner, of, teczrmedia, teczr, bullpenre, rick...</td>\n",
       "      <td>[canada]</td>\n",
       "      <td>[sean]</td>\n",
       "      <td>[sean]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[twitter, web, app]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[how, to, generate, a, swot, analysis, with, a...</td>\n",
       "      <td>[, httpstcox4wzbh5oo1, unleash, maximum, produ...</td>\n",
       "      <td>[silicon, valley, california]</td>\n",
       "      <td>[jeda, ai, world, s, first, ai, workspace, can...</td>\n",
       "      <td>[jeda, ai, world, s, first, ai, workspace, can...</td>\n",
       "      <td>[, jedaai, ai, chatgpt, gpt4, ]</td>\n",
       "      <td>[metricool]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[microsoft, research, head, peter, lee, on, th...</td>\n",
       "      <td>[biotech, advisor, likemindsglobal, beneufitre...</td>\n",
       "      <td>[dallas, tx]</td>\n",
       "      <td>[jerome, p, lisk, m, d, faan]</td>\n",
       "      <td>[jerome, p, lisk, m, d, faan]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[twitter, for, iphone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[httpstcomjmg5pco23, is, available, for, purch...</td>\n",
       "      <td>[a, great, brand, starts, with, an, even, grea...</td>\n",
       "      <td>[australia]</td>\n",
       "      <td>[dnbx, com]</td>\n",
       "      <td>[dnbx, com]</td>\n",
       "      <td>[, domains, domainnames, digitalassets, gpt, g...</td>\n",
       "      <td>[twitter, web, app]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[welcome, aboard, probeai, to, the, gpt, feedh...</td>\n",
       "      <td>[tech, entrepreneur, building, 12, public, mic...</td>\n",
       "      <td>[, 12, m, saas]</td>\n",
       "      <td>[felipe, barcelos]</td>\n",
       "      <td>[felipe, barcelos]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[twitter, web, app]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 text_wo_punct_split  \\\n",
       "0  [here, is, a, good, example, of, the, comprehe...   \n",
       "1  [how, to, generate, a, swot, analysis, with, a...   \n",
       "2  [microsoft, research, head, peter, lee, on, th...   \n",
       "3  [httpstcomjmg5pco23, is, available, for, purch...   \n",
       "4  [welcome, aboard, probeai, to, the, gpt, feedh...   \n",
       "\n",
       "                user_description_no_puctuation_split  \\\n",
       "0  [owner, of, teczrmedia, teczr, bullpenre, rick...   \n",
       "1  [, httpstcox4wzbh5oo1, unleash, maximum, produ...   \n",
       "2  [biotech, advisor, likemindsglobal, beneufitre...   \n",
       "3  [a, great, brand, starts, with, an, even, grea...   \n",
       "4  [tech, entrepreneur, building, 12, public, mic...   \n",
       "\n",
       "  user_location_no_puctuation_split  \\\n",
       "0                          [canada]   \n",
       "1     [silicon, valley, california]   \n",
       "2                      [dallas, tx]   \n",
       "3                       [australia]   \n",
       "4                   [, 12, m, saas]   \n",
       "\n",
       "                                    user_name__split  \\\n",
       "0                                             [sean]   \n",
       "1  [jeda, ai, world, s, first, ai, workspace, can...   \n",
       "2                      [jerome, p, lisk, m, d, faan]   \n",
       "3                                        [dnbx, com]   \n",
       "4                                 [felipe, barcelos]   \n",
       "\n",
       "                                     user_name_split  \\\n",
       "0                                             [sean]   \n",
       "1  [jeda, ai, world, s, first, ai, workspace, can...   \n",
       "2                      [jerome, p, lisk, m, d, faan]   \n",
       "3                                        [dnbx, com]   \n",
       "4                                 [felipe, barcelos]   \n",
       "\n",
       "                                      hashtags_split            source_split  \n",
       "0                                              [nan]     [twitter, web, app]  \n",
       "1                    [, jedaai, ai, chatgpt, gpt4, ]             [metricool]  \n",
       "2                                              [nan]  [twitter, for, iphone]  \n",
       "3  [, domains, domainnames, digitalassets, gpt, g...     [twitter, web, app]  \n",
       "4                                              [nan]     [twitter, web, app]  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With help of this stopword library there are a several words which are you need to delete\n",
    "\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "data_url_1.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0a2be502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_wo_punct_split</th>\n",
       "      <th>user_description_no_puctuation_split</th>\n",
       "      <th>user_location_no_puctuation_split</th>\n",
       "      <th>user_name__split</th>\n",
       "      <th>user_name_split</th>\n",
       "      <th>hashtags_split</th>\n",
       "      <th>source_split</th>\n",
       "      <th>text_wo_punct_split_stopwords</th>\n",
       "      <th>user_description_no_puctuation_split_stopwords</th>\n",
       "      <th>user_location_no_puctuation_split_stopwords</th>\n",
       "      <th>user_name__split_stopwords</th>\n",
       "      <th>hashtags_split_stopwords</th>\n",
       "      <th>source_split_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[here, is, a, good, example, of, the, comprehe...</td>\n",
       "      <td>[owner, of, teczrmedia, teczr, bullpenre, rick...</td>\n",
       "      <td>[canada]</td>\n",
       "      <td>[sean]</td>\n",
       "      <td>[sean]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[twitter, web, app]</td>\n",
       "      <td>[good, example, comprehension, gpt35, vs, gpt4...</td>\n",
       "      <td>[owner, teczrmedia, teczr, bullpenre, rickey, ...</td>\n",
       "      <td>[canada]</td>\n",
       "      <td>[sean]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[twitter, web, app]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[how, to, generate, a, swot, analysis, with, a...</td>\n",
       "      <td>[, httpstcox4wzbh5oo1, unleash, maximum, produ...</td>\n",
       "      <td>[silicon, valley, california]</td>\n",
       "      <td>[jeda, ai, world, s, first, ai, workspace, can...</td>\n",
       "      <td>[jeda, ai, world, s, first, ai, workspace, can...</td>\n",
       "      <td>[, jedaai, ai, chatgpt, gpt4, ]</td>\n",
       "      <td>[metricool]</td>\n",
       "      <td>[generate, swot, analysis, ai, jedaai, ai, cha...</td>\n",
       "      <td>[, httpstcox4wzbh5oo1, unleash, maximum, produ...</td>\n",
       "      <td>[silicon, valley, california]</td>\n",
       "      <td>[jeda, ai, world, first, ai, workspace, canvas]</td>\n",
       "      <td>[, jedaai, ai, chatgpt, gpt4, ]</td>\n",
       "      <td>[metricool]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[microsoft, research, head, peter, lee, on, th...</td>\n",
       "      <td>[biotech, advisor, likemindsglobal, beneufitre...</td>\n",
       "      <td>[dallas, tx]</td>\n",
       "      <td>[jerome, p, lisk, m, d, faan]</td>\n",
       "      <td>[jerome, p, lisk, m, d, faan]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[twitter, for, iphone]</td>\n",
       "      <td>[microsoft, research, head, peter, lee, applic...</td>\n",
       "      <td>[biotech, advisor, likemindsglobal, beneufitre...</td>\n",
       "      <td>[dallas, tx]</td>\n",
       "      <td>[jerome, p, lisk, faan]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[twitter, iphone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[httpstcomjmg5pco23, is, available, for, purch...</td>\n",
       "      <td>[a, great, brand, starts, with, an, even, grea...</td>\n",
       "      <td>[australia]</td>\n",
       "      <td>[dnbx, com]</td>\n",
       "      <td>[dnbx, com]</td>\n",
       "      <td>[, domains, domainnames, digitalassets, gpt, g...</td>\n",
       "      <td>[twitter, web, app]</td>\n",
       "      <td>[httpstcomjmg5pco23, available, purchase, doma...</td>\n",
       "      <td>[great, brand, starts, even, greater, name, la...</td>\n",
       "      <td>[australia]</td>\n",
       "      <td>[dnbx, com]</td>\n",
       "      <td>[, domains, domainnames, digitalassets, gpt, g...</td>\n",
       "      <td>[twitter, web, app]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[welcome, aboard, probeai, to, the, gpt, feedh...</td>\n",
       "      <td>[tech, entrepreneur, building, 12, public, mic...</td>\n",
       "      <td>[, 12, m, saas]</td>\n",
       "      <td>[felipe, barcelos]</td>\n",
       "      <td>[felipe, barcelos]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[twitter, web, app]</td>\n",
       "      <td>[welcome, aboard, probeai, gpt, feedhttpstco8b...</td>\n",
       "      <td>[tech, entrepreneur, building, 12, public, mic...</td>\n",
       "      <td>[, 12, saas]</td>\n",
       "      <td>[felipe, barcelos]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[twitter, web, app]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 text_wo_punct_split  \\\n",
       "0  [here, is, a, good, example, of, the, comprehe...   \n",
       "1  [how, to, generate, a, swot, analysis, with, a...   \n",
       "2  [microsoft, research, head, peter, lee, on, th...   \n",
       "3  [httpstcomjmg5pco23, is, available, for, purch...   \n",
       "4  [welcome, aboard, probeai, to, the, gpt, feedh...   \n",
       "\n",
       "                user_description_no_puctuation_split  \\\n",
       "0  [owner, of, teczrmedia, teczr, bullpenre, rick...   \n",
       "1  [, httpstcox4wzbh5oo1, unleash, maximum, produ...   \n",
       "2  [biotech, advisor, likemindsglobal, beneufitre...   \n",
       "3  [a, great, brand, starts, with, an, even, grea...   \n",
       "4  [tech, entrepreneur, building, 12, public, mic...   \n",
       "\n",
       "  user_location_no_puctuation_split  \\\n",
       "0                          [canada]   \n",
       "1     [silicon, valley, california]   \n",
       "2                      [dallas, tx]   \n",
       "3                       [australia]   \n",
       "4                   [, 12, m, saas]   \n",
       "\n",
       "                                    user_name__split  \\\n",
       "0                                             [sean]   \n",
       "1  [jeda, ai, world, s, first, ai, workspace, can...   \n",
       "2                      [jerome, p, lisk, m, d, faan]   \n",
       "3                                        [dnbx, com]   \n",
       "4                                 [felipe, barcelos]   \n",
       "\n",
       "                                     user_name_split  \\\n",
       "0                                             [sean]   \n",
       "1  [jeda, ai, world, s, first, ai, workspace, can...   \n",
       "2                      [jerome, p, lisk, m, d, faan]   \n",
       "3                                        [dnbx, com]   \n",
       "4                                 [felipe, barcelos]   \n",
       "\n",
       "                                      hashtags_split            source_split  \\\n",
       "0                                              [nan]     [twitter, web, app]   \n",
       "1                    [, jedaai, ai, chatgpt, gpt4, ]             [metricool]   \n",
       "2                                              [nan]  [twitter, for, iphone]   \n",
       "3  [, domains, domainnames, digitalassets, gpt, g...     [twitter, web, app]   \n",
       "4                                              [nan]     [twitter, web, app]   \n",
       "\n",
       "                       text_wo_punct_split_stopwords  \\\n",
       "0  [good, example, comprehension, gpt35, vs, gpt4...   \n",
       "1  [generate, swot, analysis, ai, jedaai, ai, cha...   \n",
       "2  [microsoft, research, head, peter, lee, applic...   \n",
       "3  [httpstcomjmg5pco23, available, purchase, doma...   \n",
       "4  [welcome, aboard, probeai, gpt, feedhttpstco8b...   \n",
       "\n",
       "      user_description_no_puctuation_split_stopwords  \\\n",
       "0  [owner, teczrmedia, teczr, bullpenre, rickey, ...   \n",
       "1  [, httpstcox4wzbh5oo1, unleash, maximum, produ...   \n",
       "2  [biotech, advisor, likemindsglobal, beneufitre...   \n",
       "3  [great, brand, starts, even, greater, name, la...   \n",
       "4  [tech, entrepreneur, building, 12, public, mic...   \n",
       "\n",
       "  user_location_no_puctuation_split_stopwords  \\\n",
       "0                                    [canada]   \n",
       "1               [silicon, valley, california]   \n",
       "2                                [dallas, tx]   \n",
       "3                                 [australia]   \n",
       "4                                [, 12, saas]   \n",
       "\n",
       "                        user_name__split_stopwords  \\\n",
       "0                                           [sean]   \n",
       "1  [jeda, ai, world, first, ai, workspace, canvas]   \n",
       "2                          [jerome, p, lisk, faan]   \n",
       "3                                      [dnbx, com]   \n",
       "4                               [felipe, barcelos]   \n",
       "\n",
       "                            hashtags_split_stopwords source_split_stopwords  \n",
       "0                                              [nan]    [twitter, web, app]  \n",
       "1                    [, jedaai, ai, chatgpt, gpt4, ]            [metricool]  \n",
       "2                                              [nan]      [twitter, iphone]  \n",
       "3  [, domains, domainnames, digitalassets, gpt, g...    [twitter, web, app]  \n",
       "4                                              [nan]    [twitter, web, app]  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(text):\n",
    "    text=[word for word in text if word not in stopword]\n",
    "    return text\n",
    "data_url_1['text_wo_punct_split_stopwords'] = data_url_1['text_wo_punct_split'].apply(lambda x: remove_stopwords(x))\n",
    "data_url_1['user_description_no_puctuation_split_stopwords'] = data_url_1['user_description_no_puctuation_split'].apply(lambda x: remove_stopwords(x))\n",
    "data_url_1['user_location_no_puctuation_split_stopwords'] = data_url_1['user_location_no_puctuation_split'].apply(lambda x: remove_stopwords(x))\n",
    "data_url_1['user_name__split_stopwords'] = data_url_1['user_name__split'].apply(lambda x: remove_stopwords(x))\n",
    "data_url_1['hashtags_split_stopwords'] = data_url_1['hashtags_split'].apply(lambda x: remove_stopwords(x))\n",
    "data_url_1['source_split_stopwords'] = data_url_1['source_split'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "\n",
    "data_url_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7d4fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
